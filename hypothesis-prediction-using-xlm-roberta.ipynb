{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"gpu","dataSources":[{"sourceId":21733,"databundleVersionId":1408234,"sourceType":"competition"}],"dockerImageVersionId":30919,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"!pip install transformers\n\nimport pandas as pd\nimport numpy as np\nimport torch\nimport torch.nn as nn\nimport torch.optim as optim\nimport seaborn as sns\nimport matplotlib.pyplot as plt\nfrom sklearn.metrics import classification_report, confusion_matrix\nfrom torch.utils.data import Dataset, DataLoader, Sampler\nfrom collections import defaultdict\nfrom transformers import AutoModelForSequenceClassification, AutoTokenizer, AdamW, get_linear_schedule_with_warmup","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true,"execution":{"iopub.status.busy":"2025-02-26T19:15:44.162464Z","iopub.execute_input":"2025-02-26T19:15:44.162752Z","iopub.status.idle":"2025-02-26T19:15:56.755794Z","shell.execute_reply.started":"2025-02-26T19:15:44.162730Z","shell.execute_reply":"2025-02-26T19:15:56.755079Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Load Data\ndata = pd.read_csv('/kaggle/input/contradictory-my-dear-watson/train.csv')\ndata['language'].unique()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-26T19:15:56.756801Z","iopub.execute_input":"2025-02-26T19:15:56.757252Z","iopub.status.idle":"2025-02-26T19:15:56.886511Z","shell.execute_reply.started":"2025-02-26T19:15:56.757216Z","shell.execute_reply":"2025-02-26T19:15:56.885670Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"dev = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n\n# Load Model and Tokenizer\nMODEL_NAME = 'joeddav/xlm-roberta-large-xnli'\ntokenizer = AutoTokenizer.from_pretrained(MODEL_NAME)\nmodel = AutoModelForSequenceClassification.from_pretrained(MODEL_NAME)\nmodel.config.hidden_dropout_prob = 0.3  # Enable dropout\nmodel.to(dev)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-26T19:15:56.888286Z","iopub.execute_input":"2025-02-26T19:15:56.888501Z","iopub.status.idle":"2025-02-26T19:16:40.914366Z","shell.execute_reply.started":"2025-02-26T19:15:56.888483Z","shell.execute_reply":"2025-02-26T19:16:40.913553Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Calculate class weights for weighted loss\nlabel_counts = data['label'].value_counts().sort_index()\nclass_weights = torch.tensor(\n    [len(data) / (3 * count) for count in label_counts.values],\n    dtype=torch.float32\n).to(dev)\nprint(\"Class weights:\", class_weights)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-26T19:16:40.915774Z","iopub.execute_input":"2025-02-26T19:16:40.916412Z","iopub.status.idle":"2025-02-26T19:16:41.224784Z","shell.execute_reply.started":"2025-02-26T19:16:40.916385Z","shell.execute_reply":"2025-02-26T19:16:41.224074Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Train-Eval Split with stratification by language and label\ndata['language'] = data['language'].astype(str)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-26T19:16:41.225579Z","iopub.execute_input":"2025-02-26T19:16:41.225816Z","iopub.status.idle":"2025-02-26T19:16:41.230437Z","shell.execute_reply.started":"2025-02-26T19:16:41.225797Z","shell.execute_reply":"2025-02-26T19:16:41.229609Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"train_data, eval_data = [], []\nfor lang, group in data.groupby('language'):\n    # For low-resource languages (less than 500 examples), use 90% for training\n    # For high-resource languages, use 80% for training\n    if len(group) < 500:\n        train_size = int(0.9 * len(group))\n    else:\n        train_size = int(0.8 * len(group))\n    \n    # Further stratify by label within each language\n    lang_train, lang_eval = [], []\n    for label, label_group in group.groupby('label'):\n        label_train_size = int(train_size * len(label_group) / len(group))\n        lang_train.append(label_group.iloc[:label_train_size])\n        lang_eval.append(label_group.iloc[label_train_size:])\n    \n    train_data.append(pd.concat(lang_train))\n    eval_data.append(pd.concat(lang_eval))\n\ntrain_data = pd.concat(train_data).reset_index(drop=True)\neval_data = pd.concat(eval_data).reset_index(drop=True)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-26T19:16:41.231311Z","iopub.execute_input":"2025-02-26T19:16:41.231621Z","iopub.status.idle":"2025-02-26T19:16:41.279863Z","shell.execute_reply.started":"2025-02-26T19:16:41.231587Z","shell.execute_reply":"2025-02-26T19:16:41.279283Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Analyze and print language distribution\nlang_train_dist = train_data['language'].value_counts().sort_index()\nlang_eval_dist = eval_data['language'].value_counts().sort_index()\nprint(\"Training language distribution:\", lang_train_dist)\nprint(\"Eval language distribution:\", lang_eval_dist)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-26T19:16:41.280559Z","iopub.execute_input":"2025-02-26T19:16:41.280820Z","iopub.status.idle":"2025-02-26T19:16:41.288636Z","shell.execute_reply.started":"2025-02-26T19:16:41.280792Z","shell.execute_reply":"2025-02-26T19:16:41.287850Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Visualize Data Distribution with histplot\nplt.figure(figsize=(12, 6))\nsns.histplot(train_data['language'], label='Train', color='skyblue', alpha=0.7)\nsns.histplot(eval_data['language'], label='Eval', color='royalblue', alpha=0.7)\nplt.title('Language Distribution in Train and Eval Sets', fontsize=14)\nplt.xlabel('Language', fontsize=12)\nplt.ylabel('Count', fontsize=12)\nplt.xticks(rotation=45, ha='right')\nplt.tight_layout()\nplt.show()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-26T19:16:41.290909Z","iopub.execute_input":"2025-02-26T19:16:41.291223Z","iopub.status.idle":"2025-02-26T19:16:41.664751Z","shell.execute_reply.started":"2025-02-26T19:16:41.291201Z","shell.execute_reply":"2025-02-26T19:16:41.663960Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"","metadata":{}},{"cell_type":"code","source":"# Dataset Class\nclass NLI_Dataset(Dataset):\n    def __init__(self, dataframe, tokenizer, max_length=128):\n        self.data = dataframe\n        self.tokenizer = tokenizer\n        self.max_length = max_length\n        \n        # Create language and label mappings for the sampler\n        self.language_indices = defaultdict(list)\n        self.label_indices = defaultdict(list)\n        \n        for idx, row in self.data.iterrows():\n            self.language_indices[row['language']].append(idx)\n            self.label_indices[row['label']].append(idx)\n\n    def __len__(self):\n        return len(self.data)\n\n    def __getitem__(self, idx):\n        row = self.data.iloc[idx]\n        # Using tokenizer more effectively with special tokens\n        tokens = self.tokenizer(\n            row['premise'], \n            row['hypothesis'], \n            truncation=True, \n            padding='max_length', \n            max_length=self.max_length, \n            return_tensors='pt'\n        )\n        return {key: val.squeeze() for key, val in tokens.items()}, torch.tensor(row['label'])","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-26T19:16:41.665861Z","iopub.execute_input":"2025-02-26T19:16:41.666106Z","iopub.status.idle":"2025-02-26T19:16:41.671833Z","shell.execute_reply.started":"2025-02-26T19:16:41.666085Z","shell.execute_reply":"2025-02-26T19:16:41.670902Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"class FixedLanguageSampler(Sampler):\n    def __init__(self, dataset, batch_size=32, langs_per_batch=5):\n        self.dataset = dataset\n        self.batch_size = batch_size\n        self.langs_per_batch = langs_per_batch\n        self.languages = list(dataset.language_indices.keys())\n        self.num_batches = len(dataset) // batch_size\n\n    def __iter__(self):\n        for _ in range(self.num_batches):\n            langs = np.random.choice(self.languages, self.langs_per_batch, replace=False)\n            batch = []\n            samples_per_lang = self.batch_size // len(langs)\n            remainder = self.batch_size % len(langs)\n            \n            for i, lang in enumerate(langs):\n                n = samples_per_lang + (1 if i < remainder else 0)\n                indices = self.dataset.language_indices[lang]\n                if len(indices) < n:\n                    selected = np.random.choice(indices, n, replace=True)\n                else:\n                    selected = np.random.choice(indices, n, replace=False)\n                batch.extend(selected)\n            yield batch\n\n    def __len__(self):\n        return self.num_batches  # Correct: number of batches","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-26T19:16:41.672692Z","iopub.execute_input":"2025-02-26T19:16:41.672952Z","iopub.status.idle":"2025-02-26T19:16:41.688622Z","shell.execute_reply.started":"2025-02-26T19:16:41.672931Z","shell.execute_reply":"2025-02-26T19:16:41.687931Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Create Datasets\ntrain_dataset = NLI_Dataset(train_data, tokenizer, max_length=150)  # Increased max length\neval_dataset = NLI_Dataset(eval_data, tokenizer, max_length=150)\n\n# Create DataLoaders with balanced sampling\ntrain_sampler = FixedLanguageSampler(train_dataset, batch_size=24, langs_per_batch=5)\ntrain_loader = DataLoader(train_dataset, batch_sampler=train_sampler)\neval_loader = DataLoader(eval_dataset, batch_size=32, shuffle=False)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-26T19:21:16.520521Z","iopub.execute_input":"2025-02-26T19:21:16.520864Z","iopub.status.idle":"2025-02-26T19:21:17.024567Z","shell.execute_reply.started":"2025-02-26T19:21:16.520835Z","shell.execute_reply":"2025-02-26T19:21:17.023644Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Training Setup with weighted loss\ncriterion = nn.CrossEntropyLoss(weight=class_weights)\noptimizer = AdamW(model.parameters(), lr=2e-5, weight_decay=0.01)  # Adjusted learning rate and weight decay\n\nnum_epochs = 3  # Increased epochs as requested\ntotal_steps = len(train_loader) * num_epochs\nnum_warmup_steps = int(total_steps * 0.1)\nscheduler = get_linear_schedule_with_warmup(\n    optimizer, \n    num_warmup_steps=num_warmup_steps, \n    num_training_steps=total_steps\n)\n\nbest_acc = 0.0","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-26T19:21:24.267643Z","iopub.execute_input":"2025-02-26T19:21:24.267944Z","iopub.status.idle":"2025-02-26T19:21:24.276741Z","shell.execute_reply.started":"2025-02-26T19:21:24.267919Z","shell.execute_reply":"2025-02-26T19:21:24.275965Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Training Loop with language-specific accuracy tracking\nmodel.train()\nfor epoch in range(num_epochs):\n    total_loss, correct, total = 0, 0, 0\n    \n    # Track accuracy by language\n    lang_correct = defaultdict(int)\n    lang_total = defaultdict(int)\n    \n    for batch_idx, batch in enumerate(train_loader):\n        optimizer.zero_grad()\n        inputs, labels = batch\n        inputs = {key: val.to(dev) for key, val in inputs.items()}\n        labels = labels.to(dev)\n        \n        # Get batch language info for logging\n        batch_indices = list(range(batch_idx * train_loader.batch_sampler.batch_size, \n                           min((batch_idx + 1) * train_loader.batch_sampler.batch_size, len(train_dataset))))\n        batch_languages = [train_data.iloc[idx]['language'] for idx in batch_indices if idx < len(train_data)]\n        \n        outputs = model(**inputs).logits\n        loss = criterion(outputs, labels)\n        loss.backward()\n        \n        # Gradient clipping to prevent exploding gradients\n        torch.nn.utils.clip_grad_norm_(model.parameters(), max_norm=1.0)\n        \n        optimizer.step()\n        scheduler.step()\n        \n        total_loss += loss.item()\n        preds = outputs.argmax(dim=1)\n        correct += (preds == labels).sum().item()\n        total += labels.size(0)\n        \n        # Log every 100 batches\n        if batch_idx % 100 == 0:\n            print(f\"Epoch {epoch+1}, Batch {batch_idx}, Loss: {loss.item():.4f}\")\n    \n    epoch_loss = total_loss / len(train_loader)\n    epoch_acc = correct / total\n    print(f\"Epoch {epoch+1}: Loss = {epoch_loss:.4f}, Accuracy = {epoch_acc:.4f}\")\n    \n    # Evaluate on each epoch\n    model.eval()\n    eval_preds, eval_true = [], []\n    eval_correct, eval_total = 0, 0\n    eval_lang_correct = defaultdict(int)\n    eval_lang_total = defaultdict(int)\n    \n    with torch.no_grad():\n        for batch in eval_loader:\n            inputs, labels = batch\n            inputs = {key: val.to(dev) for key, val in inputs.items()}\n            labels = labels.to(dev)\n            outputs = model(**inputs).logits\n            preds = outputs.argmax(dim=1)\n            \n            eval_preds.extend(preds.cpu().numpy())\n            eval_true.extend(labels.cpu().numpy())\n            \n            eval_correct += (preds == labels).sum().item()\n            eval_total += labels.size(0)\n    \n    eval_acc = eval_correct / eval_total\n    print(f\"Evaluation Accuracy: {eval_acc:.4f}\")\n    \n    # Save Best Model\n    if eval_acc > best_acc:\n        best_acc = eval_acc\n        model.save_pretrained(\"/kaggle/working/best_xlmr\")\n        tokenizer.save_pretrained(\"/kaggle/working/best_xlmr\")\n        print(\"Best model saved!\")\n    \n    # Switch back to training mode\n    model.train()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-26T19:21:43.227298Z","iopub.execute_input":"2025-02-26T19:21:43.227721Z","iopub.status.idle":"2025-02-26T19:49:10.899262Z","shell.execute_reply.started":"2025-02-26T19:21:43.227681Z","shell.execute_reply":"2025-02-26T19:49:10.897983Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Load Best Model for Final Evaluation\nmodel = AutoModelForSequenceClassification.from_pretrained(\"/kaggle/working/best_xlmr\")\nmodel.to(dev)\nmodel.eval()\n\n# Final Evaluation\npreds, true_labels = [], []\nwith torch.no_grad():\n    for batch in eval_loader:\n        inputs, labels = batch\n        inputs = {key: val.to(dev) for key, val in inputs.items()}\n        labels = labels.to(dev)\n        outputs = model(**inputs).logits\n        preds.extend(outputs.argmax(dim=1).cpu().numpy())\n        true_labels.extend(labels.cpu().numpy())\n\nprint(\"Final Classification Report:\")\nprint(classification_report(true_labels, preds, target_names=['contradiction','neutral','entailment']))\n\n# Confusion Matrix\ncm = confusion_matrix(true_labels, preds)\nplt.figure(figsize=(8, 6))\nsns.heatmap(cm, cmap=\"YlGnBu\", annot=True, fmt='g', \n           xticklabels=['contradiction','neutral','entailment'], \n           yticklabels=['contradiction','neutral','entailment'])\nplt.title(\"Confusion Matrix\")\nplt.tight_layout()\nplt.show()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-26T19:49:19.336611Z","iopub.execute_input":"2025-02-26T19:49:19.336910Z","iopub.status.idle":"2025-02-26T19:49:49.135837Z","shell.execute_reply.started":"2025-02-26T19:49:19.336887Z","shell.execute_reply":"2025-02-26T19:49:49.134866Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Load test dataset and make predictions\ntest_data = pd.read_csv('/kaggle/input/contradictory-my-dear-watson/test.csv')\nprint(f\"Loaded test dataset with {len(test_data)} samples\")\n\n# Analyze test language distribution\ntest_lang_dist = test_data['language'].value_counts()\nprint(\"Test language distribution:\", test_lang_dist)\n\n# Enhanced test dataset class with language-specific handling\nclass TestDataset(Dataset):\n    def __init__(self, dataframe, tokenizer, max_length=150):\n        self.data = dataframe\n        self.tokenizer = tokenizer\n        self.ids = dataframe['id'].values\n        self.max_length = max_length\n        self.languages = dataframe['language'].values\n\n    def __len__(self):\n        return len(self.data)\n\n    def __getitem__(self, idx):\n        row = self.data.iloc[idx]\n        tokens = self.tokenizer(\n            row['premise'], \n            row['hypothesis'], \n            truncation=True, \n            padding='max_length', \n            max_length=self.max_length, \n            return_tensors='pt'\n        )\n        return {key: val.squeeze() for key, val in tokens.items()}, self.ids[idx], self.languages[idx]\n\ntest_dataset = TestDataset(test_data, tokenizer)\ntest_loader = DataLoader(test_dataset, batch_size=32, shuffle=False)\n\n# Make language-aware predictions with temperature scaling for better calibration\npredictions = []\nprediction_ids = []\nprediction_langs = []\nwith torch.no_grad():\n    for batch in test_loader:\n        inputs, ids, langs = batch\n        inputs = {key: val.to(dev) for key, val in inputs.items()}\n        \n        # Temperature scaling for better calibration\n        outputs = model(**inputs).logits  # Soften the predictions\n        batch_preds = outputs.argmax(dim=1).cpu().numpy()\n        \n        predictions.extend(batch_preds)\n        prediction_ids.extend(ids)\n        prediction_langs.extend(langs)\n\n# Create results dataframe with predictions\nresults_df = pd.DataFrame({\n    'id': prediction_ids,\n    'prediction': predictions,\n    'language': prediction_langs\n})\n\n# Save predictions to CSV\nresults_df[['id', 'prediction']].to_csv('/kaggle/working/submission.csv', index=False)\nprint(\"Predictions saved to 'submission.csv'\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-26T19:52:28.623857Z","iopub.execute_input":"2025-02-26T19:52:28.624288Z","iopub.status.idle":"2025-02-26T19:53:45.459977Z","shell.execute_reply.started":"2025-02-26T19:52:28.624254Z","shell.execute_reply":"2025-02-26T19:53:45.459100Z"}},"outputs":[],"execution_count":null}]}